{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center><b>Data Preprocessing</b></center>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#==============================================================================\n",
    "# First step to write the python program is to take benefit out of libraries\n",
    "# already available. We will only focus on the data science related libraries.\n",
    "#==============================================================================\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Ethnicity  Height (CM)  Weight (Kg) Will survive till 70\n",
      "0     White        186.0         90.0                  Yes\n",
      "1   African        185.0         98.0                   No\n",
      "2     Asian        175.0         80.0                   No\n",
      "3     White        180.0         88.0                  Yes\n",
      "4     Asian        178.0          NaN                   No\n",
      "5     Asian        172.0         72.0                  Yes\n",
      "6   African        178.0         75.0                   No\n",
      "7     White          NaN         89.0                  Yes\n",
      "8   African        186.0         90.0                  Yes\n"
     ]
    }
   ],
   "source": [
    "#==============================================================================\n",
    "# #import data from the data file. In our case its Health.csv. \n",
    "#==============================================================================\n",
    "healthData = pd.read_csv ('Health.csv')\n",
    "print(healthData)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#==============================================================================\n",
    "# All mathematical operations will be performed on the matrix, so now we create\n",
    "# matrix for dependent variables and independent variables.\n",
    "#==============================================================================\n",
    "X = healthData.iloc [:,:-1].values\n",
    "y = healthData.iloc [:,3].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#==============================================================================\n",
    "# Handle the missing values, we can see that in dataset there are some missing\n",
    "# values, we will use strategy to impute mean of column values in these places\n",
    "#==============================================================================\n",
    "from sklearn.preprocessing import Imputer\n",
    "\n",
    "# First create an Imputer\n",
    "missingValueImputer = Imputer (missing_values = 'NaN', strategy = 'mean', axis = 0)\n",
    "\n",
    "# Set which columns imputer should perform\n",
    "missingValueImputer = missingValueImputer.fit (X[:,1:3])\n",
    "\n",
    "# update values of X with new values\n",
    "X[:,1:3] = missingValueImputer.transform(X[:,1:3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[2 186.0 90.0]\n",
      " [0 185.0 98.0]\n",
      " [1 175.0 80.0]\n",
      " [2 180.0 88.0]\n",
      " [1 178.0 85.25]\n",
      " [1 172.0 72.0]\n",
      " [0 178.0 75.0]\n",
      " [2 180.0 89.0]\n",
      " [0 186.0 90.0]]\n",
      "\n",
      "[1 0 0 1 0 1 0 1 1]\n"
     ]
    }
   ],
   "source": [
    "#==============================================================================\n",
    "# Encode the categorial data. So now instead of character values we will have\n",
    "# corresponding numerical values\n",
    "#==============================================================================\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "X_labelencoder = LabelEncoder()\n",
    "X[:, 0] = X_labelencoder.fit_transform(X[:, 0])\n",
    "print (X)\n",
    "print()\n",
    "\n",
    "# for y\n",
    "y_labelencoder = LabelEncoder ()\n",
    "y = y_labelencoder.fit_transform (y)\n",
    "print (y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[  0.     0.     1.   186.    90.  ]\n",
      " [  1.     0.     0.   185.    98.  ]\n",
      " [  0.     1.     0.   175.    80.  ]\n",
      " [  0.     0.     1.   180.    88.  ]\n",
      " [  0.     1.     0.   178.    85.25]\n",
      " [  0.     1.     0.   172.    72.  ]\n",
      " [  1.     0.     0.   178.    75.  ]\n",
      " [  0.     0.     1.   180.    89.  ]\n",
      " [  1.     0.     0.   186.    90.  ]]\n"
     ]
    }
   ],
   "source": [
    "#==============================================================================\n",
    "# Implementing OneHotEncoder to separate category variables into dummy \n",
    "# variables.\n",
    "#==============================================================================\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "X_onehotencoder = OneHotEncoder (categorical_features = [0])\n",
    "X = X_onehotencoder.fit_transform(X).toarray()\n",
    "print (X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\cross_validation.py:41: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "#==============================================================================\n",
    "# split the dataset into training and test set. We will use 80/20 approach\n",
    "#==============================================================================\n",
    "from sklearn.cross_validation import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split (X, y, test_size = 0.2, random_state = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 1.15470054 -0.63245553 -0.63245553  0.88159065  1.48988518]\n",
      " [-0.8660254   1.58113883 -0.63245553 -0.55834074 -0.02546812]\n",
      " [ 1.15470054 -0.63245553 -0.63245553  1.08729513  0.53907526]\n",
      " [ 1.15470054 -0.63245553 -0.63245553 -0.55834074 -1.24369333]\n",
      " [-0.8660254  -0.63245553  1.58113883 -0.14693177  0.30137279]\n",
      " [-0.8660254  -0.63245553  1.58113883  1.08729513  0.53907526]\n",
      " [-0.8660254   1.58113883 -0.63245553 -1.79256765 -1.60024704]]\n"
     ]
    }
   ],
   "source": [
    "#==============================================================================\n",
    "# Feature scaling is to bring all the independent variables in a dataset into\n",
    "# same scale, to avoid any variable dominating  the model. Here we will not \n",
    "# transform the dependent variables.\n",
    "#==============================================================================\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "independent_scalar = StandardScaler()\n",
    "X_train = independent_scalar.fit_transform (X_train) #fit and transform\n",
    "X_test = independent_scalar.transform (X_test) # only transform\n",
    "print(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
